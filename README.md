# EfficientNet
---

A variant of realisation of [EfficientNet][1] by keras and tensorflow.

## Some references:
---
1. [Finetuning of ImageNet pretrained EfficientNet-B0 on CIFAR-100 (source)][2]
2. [Official TPU realisation (source)][3]
3. [MBConv block][4]
4. [Inverted Residuals and Linear Bottlenecks][5]
5. [Width vs depth in residual networks][6]
6. [Squeeze-and-Excitation Networks][7]
7. [Swish activation][8]


[1]: https://arxiv.org/abs/1905.11946 (Mingxing Tan, Quoc V. Le EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks)
[2]: https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/EfficientNet_Cifar100_finetuning.ipynb (Finetuning of ImageNet pretrained EfficientNet-B0 on CIFAR-100)
[3]: https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/ (Mingxing Tan, Quoc V. Le source)
[4]: https://arxiv.org/pdf/1807.11626.pdf (Mingxing Tan,et. a. MnasNet: Platform-Aware Neural Architecture Search for Mobile)
[5]: https://arxiv.org/pdf/1801.04381.pdf (Mark Sandler, Andrew Howard MobileNetV2: Inverted Residuals and Linear Bottlenecks)
[6]: https://arxiv.org/pdf/1605.07146.pdf (Sergey Zagoruyko, Nikos Komodakis Wide Residual Networks)
[7]: https://arxiv.org/pdf/1709.01507.pdf (Jie Hu et.a. Squeeze-and-Excitation Networks)
[8]: https://arxiv.org/pdf/1710.05941.pdf (Prajit Ramachandran, Barret Zoph, Quoc V. Le SEARCHING FOR ACTIVATION FUNCTIONS)
